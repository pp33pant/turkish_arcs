{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Muhtesem Yuzyil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e070d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d67747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast table saved to 'muhtesemyuzyil.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://en.wikipedia.org/wiki/Muhte%C5%9Fem_Y%C3%BCzy%C4%B1l\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the section with the \"Broadcast\" headline\n",
    "    broadcast_section = soup.find('span', {'id': 'Broadcast'})\n",
    "\n",
    "    # Find the table within the Broadcast section\n",
    "    table = broadcast_section.find_next('table', {'class': 'wikitable'})\n",
    "\n",
    "    # Extract the table data into a pandas DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the desired filename\n",
    "    df.to_csv('muhtesemyuzyil.csv', index=False)\n",
    "    print(\"Broadcast table saved to 'muhtesemyuzyil.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248ce78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EZEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0f3eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Country                                          Days\n",
      "0                  Albania                              RTV Klan in 2011\n",
      "1                Argentina                        Telefefrom 11 May 2015\n",
      "2               Azerbaijan                     ARBfrom 20 September 2020\n",
      "3               Bangladesh                Deepto TVfrom 13 November 2018\n",
      "4   Bosnia and Herzegovina                                   BHRTin 2011\n",
      "5                   Brazil                      Rede Bandeirantesin 2016\n",
      "6                 Bulgaria                                Nova TVin 2012\n",
      "7                    Chile                 Chilean TV channelMegain 2014\n",
      "8                 Colombia                     Caracol Televisiónin 2015\n",
      "9                  Croatia                   RTL Televizijain 2011, 2012\n",
      "10          Czech Republic                             Prima Lovein 2011\n",
      "11                  Greece                                ANT1 TVin 2011\n",
      "12                 Hungary                              RTL Klub in 2011\n",
      "13                    Iran        Gem TV in 2010 and Gem Classic in 2011\n",
      "14                    Iraq                      Kurdsat in 2016 and 2017\n",
      "15                  Israel                                     Viva Plus\n",
      "16              Kazakhstan                                  Habarin 2011\n",
      "17                  Kosovo                                  RTV21in 2013\n",
      "18               Lithuania                               LNKin 2013–2014\n",
      "19                 Morocco                                            2M\n",
      "20         North Macedonia                              Sitel TV in 2011\n",
      "21                Pakistan                             Geo Kahaniin 2013\n",
      "22                    Peru                                 Latinain 2015\n",
      "23                 Romania                   Kanal D Romaniain 2010–2011\n",
      "24            Saudi Arabia                                   MBC4in 2012\n",
      "25                  Serbia      Prvafrom 18 June 2012 to 14 October 2012\n",
      "26                Slovakia  TV Domafrom 10 April 2012 to 3 December 2012\n",
      "27                   Spain                   Nova (Spain TV channel)2018\n",
      "28               Sri Lanka                                       series.\n",
      "29                 Tunisia                                 NessmaTV 2019\n",
      "30    United Arab Emirates                      Abu Dhabi Al Oulain 2010\n",
      "31           United States                                       Netflix\n",
      "Ezel in other languages table saved to 'ezel_languages.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://en.wikipedia.org/wiki/Ezel_(TV_series)\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the section with the \"Ezel in other languages\" headline\n",
    "    languages_section = soup.find('span', {'id': 'Ezel_in_other_languages'})\n",
    "\n",
    "    # Find the next sibling (which is the list)\n",
    "    language_list = languages_section.find_next('ul')\n",
    "\n",
    "    # Initialize empty lists to store data\n",
    "    countries = []\n",
    "    days = []\n",
    "\n",
    "    # Iterate through list items\n",
    "    for li in language_list.find_all('li'):\n",
    "        # Extract the country name from the link's title attribute\n",
    "        country = li.find('a').get('title', '')\n",
    "\n",
    "        # Extract the date from the text content of the list item\n",
    "        date = li.get_text(strip=True).split('on')[-1]\n",
    "\n",
    "        # Append data to lists\n",
    "        countries.append(country)\n",
    "        days.append(date)\n",
    "\n",
    "    # Create a DataFrame from the lists\n",
    "    df = pd.DataFrame({'Country': countries, 'Days': days})\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the desired filename\n",
    "    df.to_csv('ezel_languages.csv', index=False)\n",
    "    print(\"Ezel in other languages table saved to 'ezel_languages.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASk i memnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c191ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Country\n",
      "0                                             Algeria\n",
      "1                                     Turkey –Kanal D\n",
      "2                      Bosnia & Herzegovina –Hayat TV\n",
      "3                                Afghanistan –Tolo TV\n",
      "4            Pakistan –Urdu 1(Dubbed inUrdu language)\n",
      "5                                            Pakistan\n",
      "6   America and Europe –Rishtey TV[12](Dubbed inHi...\n",
      "7    Bangladesh –Channel I(Dubbed inBengali language)\n",
      "8                                 Saudi Arabia –MBC 4\n",
      "9                                               Egypt\n",
      "10                                       Lebanon –LBC\n",
      "11  Iran –GEM ClassicChannel (Dubbed inPersian lan...\n",
      "12        Bulgaria –bTV,bTV Lady,Nova TV,Diema Family\n",
      "13                                  Montenegro –TV In\n",
      "14                                  Morocco –2M Maroc\n",
      "15                                 Tunisia –Nessma TV\n",
      "16                           Croatia –Nova TV,Doma TV\n",
      "17                                    Serbia –Prva TV\n",
      "18                                       Hungary –TV2\n",
      "19                                       Greece –ANT1\n",
      "20                                   Slovenia –POP TV\n",
      "21                                  Slovakia –TV Doma\n",
      "22                             Romania –Kanal D,Pro 2\n",
      "23              China –XJTV(Dubbed inUyghur language)\n",
      "24                                             Israel\n",
      "25                                         Kazakhstan\n",
      "26                                         Uzbekistan\n",
      "27                                 Macedonia –Kanal 5\n",
      "28                                     Lithuania –LNK\n",
      "29                                   Albania –Klan TV\n",
      "30                                Georgia –Maestro TV\n",
      "31                                    Chile –Canal 13\n",
      "32                                             Latvia\n",
      "33                                   Estonia –Kanal 2\n",
      "34                                   Ecuador –Gama TV\n",
      "35                            Peru –Latina Televisión\n",
      "36                               Paraguay –Telefuturo\n",
      "37                                  Argentina –Telefe\n",
      "38         Brazil –Band(Dubbed inPortuguese language)\n",
      "39                       Colombia –Caracol Televisión\n",
      "40                                  Mexico –Imagen TV\n",
      "41                                     Czech Republic\n",
      "42                                  Ethiopia –Kana TV\n",
      "43  United States -UnivisionDubbed in Spanish. Set...\n",
      "International broadcasts for Aşk-ı Memnu table saved to 'askimemnu.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://en.wikipedia.org/wiki/A%C5%9Fk-%C4%B1_Memnu_(2008_TV_series)#International_broadcasts\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the section with the \"International_broadcasts\" headline\n",
    "    broadcasts_section = soup.find('span', {'id': 'International_broadcasts'})\n",
    "\n",
    "    # Find the next sibling (which is the list)\n",
    "    broadcasts_list = broadcasts_section.find_next('ul')\n",
    "\n",
    "    # Initialize empty lists to store data\n",
    "    countries = []\n",
    "\n",
    "    # Iterate through list items\n",
    "    for li in broadcasts_list.find_all('li'):\n",
    "        # Extract the country name from the text content of each list item\n",
    "        country = li.get_text(strip=True).split(' – ')[0].split(' - ')[0]\n",
    "\n",
    "        # Append data to the list\n",
    "        countries.append(country)\n",
    "\n",
    "    # Create a DataFrame from the list\n",
    "    df = pd.DataFrame({'Country': countries})\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the desired filename\n",
    "    df.to_csv('askimemnu.csv', index=False)\n",
    "    print(\"International broadcasts for Aşk-ı Memnu table saved to 'askimemnu.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3bcfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Oyle bir gecer zaman ki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f941f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast table saved to 'oylebirgecer.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://en.wikipedia.org/wiki/%C3%96yle_Bir_Ge%C3%A7er_Zaman_ki#International_broadcasters\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the section with the \"Broadcast\" headline in a case-insensitive manner\n",
    "    broadcast_section = soup.find('span', {'id': 'International_broadcasters'} or {'id': 'international_broadcasters'})\n",
    "\n",
    "    # Find the table within the Broadcast section\n",
    "    table = broadcast_section.find_next('table', {'class': 'wikitable'})\n",
    "\n",
    "    # Extract the table data into a pandas DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the desired filename\n",
    "    df.to_csv('oylebirgecer.csv', index=False)\n",
    "    print(\"Broadcast table saved to 'oylebirgecer.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33121284",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fatmagül'ün Suçu Ne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30b0418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Country                                            Details\n",
      "0               Bangladesh    on Deepto TV with the title ফাতমাগুল (Fatmagul)\n",
      "1                    India          on Zee Zindagi with the title of Fatmagul\n",
      "2                 Pakistan  on Urdu 1 with the title of فاطمہ گل - آخر میر...\n",
      "3                  Albania         on Albanian Screen with the title Fatmagyl\n",
      "4   Bosnia and Herzegovina                              title Izgubljena čast\n",
      "5                   Israel           on Viva with the title פטמגול (Fatmagul)\n",
      "6             Saudi Arabia               on MBC4 With the title فاطمة (Fatma)\n",
      "7              Arab League                 n Fox with the title فاطمة (Fatma)\n",
      "8              Afghanistan               on Tolo TV with the title Fatima Gul\n",
      "9                 Bulgaria  on BTV, BTV Lady with the title Пепел от рози ...\n",
      "10                 Croatia  on Nova TV with the title Izgubljena čast (Los...\n",
      "11                  Serbia  on Prva TV with the title Izgubljena čast (Los...\n",
      "12              Montenegro  on TV Vijesti with the title Izgubljena čast (...\n",
      "13                  France                on TV5Monde with the title Fatmagul\n",
      "14       Georgia (country)                        V with the title უდანაშაულო\n",
      "15                  Greece            on Mega Channel with the title Fatmagul\n",
      "16                  Kosovo                   on RTV21 with the title Fatmagyl\n",
      "17                    Iran                on GEM/River with the title فاطماگل\n",
      "18                 Lebanon                       on LBCI with the title Fatma\n",
      "19                   Spain                    on Nova with the title Fatmagul\n",
      "20                  Russia  on STS \"Без вины виноватая\" (Guilty Without Gu...\n",
      "21                 England  on Turkish Dramas with the title \"What is Fatm...\n",
      "22               Indonesia                    on ANTV with the title Fatmagul\n",
      "23                 Morocco             on medi 1 With the title فاطمة (Fatma)\n",
      "24         North Macedonia  el TV with the title Судбината на Фатмаѓул (Fa...\n",
      "25                 Estonia  on Kanal 2 with the title Süütu süüdlane (Inno...\n",
      "26                 Ukraine  on 1+1 \"У чому вина Фатмагюль?\" (Where is Fatm...\n",
      "27                Slovakia                 on TV Doma with the title Fatmagul\n",
      "28               Lithuania  on LNK with the title Be kaltės kalta (Guilty ...\n",
      "29                   Chile  on Mega with the title ¿Qué culpa tiene Fatmag...\n",
      "30               Argentina  on Telefé with the title ¿Qué culpa tiene Fatm...\n",
      "31                Slovenia               on Planet TV with the title Fatmagul\n",
      "32                    Peru  on Frecuencia Latina with the title ¿Qué culpa...\n",
      "33          Czech Republic  Love with the title Krásná fatmagul (Beautiful...\n",
      "34                  Brazil  on Rede Bandeirantes with the title Fatmagül -...\n",
      "35                Ethiopia                      on Kana TV with the title ቅጣት\n",
      "36             Puerto Rico  on WAPA-TV and Telemundo PR with the title ¿Qu...\n",
      "37                Honduras  on Canal 5 with the title ¿Qué culpa tiene Fat...\n",
      "38                 Romania                 on Kanal D with the title Fatmagül\n",
      "39                 Hungary                     on TV2 with the title Fatmagül\n",
      "40                  Poland            on TVP 1 with the title Grzech Fatmagül\n",
      "41            South Africa  on eExtra with the title FATMAGÜL in English d...\n",
      "42                 Belgium                on RTL Play with the title Fatmagül\n",
      "43                  Mexico  on Azteca Uno and Nu9ve with the title ¿Qué cu...\n",
      "44           United States  on Univision with the title ¿Qué culpa tiene F...\n",
      "International broadcasts for Fatmagul table saved to 'fatmagul.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://en.wikipedia.org/wiki/Fatmag%C3%BCl%27%C3%BCn_Su%C3%A7u_Ne%3F#International_broadcasts\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the section with the \"International_broadcasts\" headline\n",
    "    broadcasts_section = soup.find('span', {'id': 'International_broadcasts'})\n",
    "\n",
    "    # Find the next sibling (which is the list)\n",
    "    broadcasts_list = broadcasts_section.find_next('ul')\n",
    "\n",
    "    # Initialize empty lists to store data\n",
    "    countries = []\n",
    "    details = []\n",
    "\n",
    "    # Iterate through list items\n",
    "    for li in broadcasts_list.find_all('li'):\n",
    "        # Extract the country name from the text content of each list item\n",
    "        country = li.find('a').get('title')\n",
    "\n",
    "        # Extract the details following the country name\n",
    "        detail = ' '.join(li.stripped_strings)[len(country) + 1:]\n",
    "\n",
    "        # Append data to the lists\n",
    "        countries.append(country)\n",
    "        details.append(detail)\n",
    "\n",
    "    # Create a DataFrame from the lists\n",
    "    df = pd.DataFrame({'Country': countries, 'Details': details})\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the desired filename\n",
    "    df.to_csv('fatmagul.csv', index=False)\n",
    "    print(\"International broadcasts for Fatmagul table saved to 'fatmagul.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58dd428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast table saved to 'medcezir.csv'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Medcezir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18220/788792303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Failed to retrieve the page. Status code: {response.status_code}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mMedcezir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Medcezir' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://en.wikipedia.org/wiki/Medcezir#International_broadcasting\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the section with the \"Broadcast\" headline\n",
    "    broadcast_section = soup.find('span', {'id': 'International_broadcasting'})\n",
    "\n",
    "    # Find the table within the Broadcast section\n",
    "    table = broadcast_section.find_next('table', {'class': 'wikitable'})\n",
    "\n",
    "    # Extract the table data into a pandas DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the desired filename\n",
    "    df.to_csv('medcezir.csv', index=False)\n",
    "    print(\"Broadcast table saved to 'medcezir.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b254b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All IDs on the page: ['vector-main-menu-dropdown', 'vector-main-menu-dropdown-checkbox', 'vector-main-menu-dropdown-label', 'vector-main-menu-unpinned-container', 'vector-main-menu', 'p-navigation', 'n-mainpage-description', 'n-contents', 'n-currentevents', 'n-randompage', 'n-aboutsite', 'n-contactpage', 'n-sitesupport', 'p-interaction', 'n-help', 'n-introduction', 'n-portal', 'n-recentchanges', 'n-upload', 'p-search', '', 'searchform', 'simpleSearch', 'searchInput', 'p-vector-user-menu-preferences', 'p-vector-user-menu-userpage', 'p-vector-user-menu-notifications', 'p-vector-user-menu-overflow', 'pt-createaccount-2', 'pt-login-2', 'vector-user-links-dropdown', 'vector-user-links-dropdown-checkbox', 'vector-user-links-dropdown-label', 'p-personal', 'pt-createaccount', 'pt-login', 'p-user-menu-anon-editor', 'pt-anoncontribs', 'pt-anontalk', 'siteNotice', 'mw-navigation', 'mw-panel', 'vector-main-menu-pinned-container', 'mw-panel-toc', 'vector-toc-pinned-container', 'vector-toc', 'mw-panel-toc-list', 'toc-mw-content-text', 'toc-Plot', 'toc-Plot-sublist', 'toc-Cast_and_characters', 'toc-Cast_and_characters-sublist', 'toc-Main_cast', 'toc-Main_cast-sublist', 'toc-Recurring', 'toc-Recurring-sublist', 'toc-Production', 'toc-Production-sublist', 'toc-Development', 'toc-Development-sublist', 'toc-Crew', 'toc-Crew-sublist', 'toc-Music', 'toc-Music-sublist', 'toc-Filming', 'toc-Filming-sublist', 'toc-Reception', 'toc-Reception-sublist', 'toc-Critical_reception', 'toc-Critical_reception-sublist', 'toc-Popular_culture', 'toc-Popular_culture-sublist', 'toc-Ratings', 'toc-Ratings-sublist', 'toc-Awards_and_nominations', 'toc-Awards_and_nominations-sublist', 'toc-International_broadcasting', 'toc-International_broadcasting-sublist', 'toc-References', 'toc-References-sublist', 'content', 'vector-page-titlebar-toc', 'vector-page-titlebar-toc-checkbox', 'vector-page-titlebar-toc-label', 'vector-page-titlebar-toc-unpinned-container', 'firstHeading', 'p-lang-btn', 'p-lang-btn-checkbox', 'p-lang-btn-label', 'left-navigation', 'p-associated-pages', 'ca-nstab-main', 'ca-talk', 'p-variants', 'p-variants-checkbox', 'p-variants-label', 'p-variants', 'right-navigation', 'p-views', 'ca-view', 'ca-edit', 'ca-history', 'vector-page-tools-dropdown', 'vector-page-tools-dropdown-checkbox', 'vector-page-tools-dropdown-label', 'vector-page-tools-unpinned-container', 'vector-page-tools', 'p-cactions', 'ca-more-view', 'ca-more-edit', 'ca-more-history', 'p-tb', 't-whatlinkshere', 't-recentchangeslinked', 't-upload', 't-specialpages', 't-permalink', 't-info', 't-cite', 't-urlshortener', 't-wikibase', 'p-coll-print_export', 'coll-download-as-rl', 't-print', 'p-wikibase-otherprojects', 'vector-page-tools-pinned-container', 'bodyContent', 'siteSub', 'contentSub', 'mw-content-subtitle', 'mw-content-text', 'cite_ref-1', 'cite_ref-sizegore.com_2-0', 'cite_ref-turkiyegazetesi.com.tr_3-0', 'cite_ref-4', 'Plot', 'Cast_and_characters', 'Main_cast', 'Recurring', 'Production', 'Development', 'cite_ref-5', 'cite_ref-6', 'cite_ref-7', 'cite_ref-8', 'cite_ref-sizegore.com_2-1', 'cite_ref-turkiyegazetesi.com.tr_3-1', 'cite_ref-9', 'Crew', 'cite_ref-10', 'cite_ref-11', 'cite_ref-12', 'cite_ref-ayyapim.tv_13-0', 'cite_ref-14', 'cite_ref-15', 'cite_ref-16', 'Music', 'cite_ref-ayyapim.tv_13-1', 'cite_ref-17', 'cite_ref-18', 'cite_ref-19', 'cite_ref-20', 'cite_ref-21', 'cite_ref-22', 'cite_ref-23', 'cite_ref-24', 'cite_ref-25', 'cite_ref-26', 'cite_ref-27', 'cite_ref-28', 'cite_ref-29', 'cite_ref-30', 'cite_ref-31', 'cite_ref-32', 'cite_ref-33', 'cite_ref-34', 'cite_ref-35', 'Filming', 'cite_ref-36', 'cite_ref-37', 'cite_ref-38', 'cite_ref-39', 'cite_ref-40', 'Reception', 'Critical_reception', 'cite_ref-41', 'cite_ref-42', 'cite_ref-43', 'cite_ref-44', 'cite_ref-45', 'cite_ref-46', 'cite_ref-47', 'cite_ref-48', 'cite_ref-49', 'cite_ref-50', 'cite_ref-51', 'cite_ref-52', 'cite_ref-53', 'cite_ref-54', 'cite_ref-55', 'cite_ref-56', 'cite_ref-blog.milliyet.com.tr_57-0', 'cite_ref-58', 'cite_ref-59', 'cite_ref-60', 'cite_ref-61', 'Popular_culture', 'cite_ref-62', 'cite_ref-63', 'cite_ref-64', 'cite_ref-65', 'cite_ref-66', 'cite_ref-67', 'Ratings', 'cite_ref-68', 'cite_ref-69', 'cite_ref-sacitaslan.com_70-0', 'cite_ref-blog.milliyet.com.tr_57-1', 'cite_ref-71', 'cite_ref-72', 'cite_ref-73', 'cite_ref-74', 'Awards_and_nominations', 'cite_ref-75', 'cite_ref-76', 'cite_ref-77', 'cite_ref-78', 'cite_ref-79', 'International_broadcasting', 'cite_ref-80', 'cite_ref-81', 'cite_ref-82', 'References', 'cite_note-1', 'cite_note-sizegore.com-2', 'cite_note-turkiyegazetesi.com.tr-3', 'cite_note-4', 'cite_note-5', 'cite_note-6', 'cite_note-7', 'cite_note-8', 'cite_note-9', 'cite_note-10', 'cite_note-11', 'cite_note-12', 'cite_note-ayyapim.tv-13', 'cite_note-14', 'cite_note-15', 'cite_note-16', 'cite_note-17', 'cite_note-18', 'cite_note-19', 'cite_note-20', 'cite_note-21', 'cite_note-22', 'cite_note-23', 'cite_note-24', 'cite_note-25', 'cite_note-26', 'cite_note-27', 'cite_note-28', 'cite_note-29', 'cite_note-30', 'cite_note-31', 'cite_note-32', 'cite_note-33', 'cite_note-34', 'cite_note-35', 'cite_note-36', 'cite_note-37', 'cite_note-38', 'cite_note-39', 'cite_note-40', 'cite_note-41', 'cite_note-42', 'cite_note-43', 'cite_note-44', 'cite_note-45', 'cite_note-46', 'cite_note-47', 'cite_note-48', 'cite_note-49', 'cite_note-50', 'cite_note-51', 'cite_note-52', 'cite_note-53', 'cite_note-54', 'cite_note-55', 'cite_note-56', 'cite_note-blog.milliyet.com.tr-57', 'cite_note-58', 'cite_note-59', 'cite_note-60', 'cite_note-61', 'cite_note-62', 'cite_note-63', 'cite_note-64', 'cite_note-65', 'cite_note-66', 'cite_note-67', 'cite_note-68', 'cite_note-69', 'cite_note-sacitaslan.com-70', 'cite_note-71', 'cite_note-72', 'cite_note-73', 'cite_note-74', 'cite_note-75', 'cite_note-76', 'cite_note-77', 'cite_note-78', 'cite_note-79', 'cite_note-80', 'cite_note-81', 'cite_note-82', 'The_O.C.', 'catlinks', 'mw-normal-catlinks', 'mw-hidden-catlinks', 'footer', 'footer-info', 'footer-info-lastmod', 'footer-info-copyright', 'footer-places', 'footer-places-privacy', 'footer-places-about', 'footer-places-disclaimers', 'footer-places-contact', 'footer-places-wm-codeofconduct', 'footer-places-developers', 'footer-places-statslink', 'footer-places-cookiestatement', 'footer-places-mobileview', 'footer-icons', 'footer-copyrightico', 'footer-poweredbyico', 'p-dock-bottom', '']\n",
      "Broadcast section not found.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
